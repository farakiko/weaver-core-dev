{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb702c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import uproot\n",
    "import glob\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d8a1d30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: ../datafiles/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../datafiles/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "160bff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: ../datafiles/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/240-250/parquet: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../datafiles/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/240-250/parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d9b4c71",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4258556986.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pd.read_parquet(../datafiles/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/240-250/parquet)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pd.read_parquet(../datafiles/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/240-250/parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566d3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dir_ in os.listdir(\"../datafiles/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/\"):\n",
    "#     if \".parquet\" in dir_:\n",
    "#         continue\n",
    "            \n",
    "#     print(f\"../datafiles/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/{dir_}/parquet\")\n",
    "    \n",
    "#     a = pd.read_parquet(f\"../datafiles/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/{dir_}/parquet/\")\n",
    "    \n",
    "#     a.to_parquet(f\"../datafiles/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/{dir_}.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e749f7b",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f37bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_vars(df):\n",
    "    \n",
    "    df = df.rename(columns={\n",
    "        \"mt_lep_met\": \"lep_met_mt\", \n",
    "        \"lep_dR_fj\": \"lep_fj_dr\",\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# we must add the \"fj_isVBF\" & \"fj_isggF\" labels that we forgot to include in the processor\n",
    "def postprocess(df, sample):\n",
    "    if \"HToWW\" in sample:        \n",
    "        if \"VBF\" in sample:\n",
    "            df[\"fj_isggF\"] = 0\n",
    "            df[\"fj_isVBF\"] = 1\n",
    "        elif \"GluGluHToWW\" in sample:\n",
    "            df[\"fj_isggF\"] = 1\n",
    "            df[\"fj_isVBF\"] = 0      \n",
    "    else:\n",
    "        df[\"fj_isggF\"] = 0\n",
    "        df[\"fj_isVBF\"] = 0  \n",
    "\n",
    "    df = rename_vars(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b96bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing GluGluHToWW_Pt-200ToInf_M-125\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "OUTPATH = \"../datafiles/TaggerInputFeb9_2017/\"\n",
    "\n",
    "for sample in os.listdir(f\"{OUTPATH}/\"):\n",
    "    if \"DS_Store\" in sample:\n",
    "        continue    \n",
    "    if \"run_skimmer\" in sample:\n",
    "        continue    \n",
    "    if \"inputprocessor\" in sample:\n",
    "        continue            \n",
    "\n",
    "    print(f\"Processing {sample}\")\n",
    "\n",
    "    outdir = f\"{OUTPATH}/{sample}/outfiles\"        \n",
    "    df = pd.read_parquet(glob.glob(f\"{outdir}/*.parquet\"))\n",
    "    df = postprocess(df, sample)\n",
    "\n",
    "    df_train, df_test = sklearn.model_selection.train_test_split(df, test_size=0.4)\n",
    "\n",
    "    os.system(f\"mkdir -p {outdir}/train\")\n",
    "    with uproot.recreate(f\"{outdir}/train/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "        rfile[\"Events\"] = ak.Array(df_train.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "    os.system(f\"mkdir -p {outdir}/test\")            \n",
    "    with uproot.recreate(f\"{outdir}/test/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "        rfile[\"Events\"] = ak.Array(df_test.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "    print(\"--------------------------\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65034801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-10.parquet      1540-1550.parquet 210-220.parquet   480-490.parquet\r\n",
      "10-20.parquet     1550-1560.parquet 2100-2110.parquet 490-500.parquet\r\n",
      "100-110.parquet   1560-1570.parquet 2110-2120.parquet 50-60.parquet\r\n",
      "1000-1010.parquet 1570-1580.parquet 2120-2130.parquet 500-510.parquet\r\n",
      "1010-1020.parquet 1580-1590.parquet 2130-2140.parquet 510-520.parquet\r\n",
      "1020-1030.parquet 1590-1600.parquet 2140-2150.parquet 520-530.parquet\r\n",
      "1030-1040.parquet 160-170.parquet   2150-2160.parquet 530-540.parquet\r\n",
      "1040-1050.parquet 1600-1610.parquet 2160-2170.parquet 540-550.parquet\r\n",
      "1050-1060.parquet 1610-1620.parquet 2170-2180.parquet 550-560.parquet\r\n",
      "1060-1070.parquet 1620-1630.parquet 2180-2190.parquet 560-570.parquet\r\n",
      "1070-1080.parquet 1630-1640.parquet 2190-2200.parquet 570-580.parquet\r\n",
      "1080-1090.parquet 1640-1650.parquet 220-230.parquet   580-590.parquet\r\n",
      "1090-1100.parquet 1650-1660.parquet 2200-2210.parquet 590-600.parquet\r\n",
      "110-120.parquet   1660-1670.parquet 2210-2220.parquet 60-70.parquet\r\n",
      "1100-1110.parquet 1670-1680.parquet 2220-2230.parquet 600-610.parquet\r\n",
      "1110-1120.parquet 1680-1690.parquet 2230-2240.parquet 610-620.parquet\r\n",
      "1120-1130.parquet 1690-1700.parquet 2240-2250.parquet 620-630.parquet\r\n",
      "1130-1140.parquet 170-180.parquet   2250-2260.parquet 630-640.parquet\r\n",
      "1140-1150.parquet 1700-1710.parquet 2260-2270.parquet 640-650.parquet\r\n",
      "1150-1160.parquet 1710-1720.parquet 2270-2280.parquet 650-660.parquet\r\n",
      "1160-1170.parquet 1720-1730.parquet 2280-2290.parquet 660-670.parquet\r\n",
      "1170-1180.parquet 1730-1740.parquet 2290-2300.parquet 670-680.parquet\r\n",
      "1180-1190.parquet 1740-1750.parquet 230-240.parquet   680-690.parquet\r\n",
      "1190-1200.parquet 1750-1760.parquet 2300-2310.parquet 690-700.parquet\r\n",
      "120-130.parquet   1760-1770.parquet 2310-2320.parquet 70-80.parquet\r\n",
      "1200-1210.parquet 1770-1780.parquet 2320-2330.parquet 700-710.parquet\r\n",
      "1210-1220.parquet 1780-1790.parquet 2330-2340.parquet 710-720.parquet\r\n",
      "1220-1230.parquet 1790-1800.parquet 2340-2350.parquet 720-730.parquet\r\n",
      "1230-1240.parquet 180-190.parquet   2350-2360.parquet 730-740.parquet\r\n",
      "1240-1250.parquet 1800-1810.parquet 2360-2370.parquet 740-750.parquet\r\n",
      "1250-1260.parquet 1810-1820.parquet 2370-2380.parquet 750-760.parquet\r\n",
      "1260-1270.parquet 1820-1830.parquet 2380-2390.parquet 760-770.parquet\r\n",
      "1270-1280.parquet 1830-1840.parquet 2390-2400.parquet 770-780.parquet\r\n",
      "1280-1290.parquet 1840-1850.parquet 240-250.parquet   780-790.parquet\r\n",
      "1290-1300.parquet 1850-1860.parquet 2400-2410.parquet 790-800.parquet\r\n",
      "130-140.parquet   1860-1870.parquet 2410-2420.parquet 80-90.parquet\r\n",
      "1300-1310.parquet 1870-1880.parquet 2420-2430.parquet 800-810.parquet\r\n",
      "1310-1320.parquet 1880-1890.parquet 250-260.parquet   810-820.parquet\r\n",
      "1320-1330.parquet 1890-1900.parquet 260-270.parquet   820-830.parquet\r\n",
      "1330-1340.parquet 190-200.parquet   270-280.parquet   830-840.parquet\r\n",
      "1340-1350.parquet 1900-1910.parquet 280-290.parquet   840-850.parquet\r\n",
      "1350-1360.parquet 1910-1920.parquet 290-300.parquet   850-860.parquet\r\n",
      "1360-1370.parquet 1920-1930.parquet 30-40.parquet     860-870.parquet\r\n",
      "1370-1380.parquet 1930-1940.parquet 300-310.parquet   870-880.parquet\r\n",
      "1380-1390.parquet 1940-1950.parquet 310-320.parquet   880-890.parquet\r\n",
      "1390-1400.parquet 1950-1960.parquet 320-330.parquet   890-900.parquet\r\n",
      "140-150.parquet   1960-1970.parquet 330-340.parquet   90-100.parquet\r\n",
      "1400-1410.parquet 1970-1980.parquet 340-350.parquet   900-910.parquet\r\n",
      "1410-1420.parquet 1980-1990.parquet 350-360.parquet   910-920.parquet\r\n",
      "1420-1430.parquet 1990-2000.parquet 360-370.parquet   920-930.parquet\r\n",
      "1430-1440.parquet 20-30.parquet     370-380.parquet   930-940.parquet\r\n",
      "1440-1450.parquet 200-210.parquet   380-390.parquet   940-950.parquet\r\n",
      "1450-1460.parquet 2000-2010.parquet 390-400.parquet   950-960.parquet\r\n",
      "1460-1470.parquet 2010-2020.parquet 40-50.parquet     960-970.parquet\r\n",
      "1470-1480.parquet 2020-2030.parquet 400-410.parquet   970-980.parquet\r\n",
      "1480-1490.parquet 2030-2040.parquet 410-420.parquet   980-990.parquet\r\n",
      "1490-1500.parquet 2040-2050.parquet 420-430.parquet   990-1000.parquet\r\n",
      "150-160.parquet   2050-2060.parquet 430-440.parquet   \u001b[34mtest\u001b[m\u001b[m\r\n",
      "1500-1510.parquet 2060-2070.parquet 440-450.parquet   \u001b[34mtrain\u001b[m\u001b[m\r\n",
      "1510-1520.parquet 2070-2080.parquet 450-460.parquet\r\n",
      "1520-1530.parquet 2080-2090.parquet 460-470.parquet\r\n",
      "1530-1540.parquet 2090-2100.parquet 470-480.parquet\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../datafiles/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac405cc",
   "metadata": {},
   "source": [
    "# Inspecting NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b79b856e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting file ../datafiles/TaggerInputFeb9_2017//GluGluHToWW_Pt-200ToInf_M-125/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInputFeb9_2017//GluGluHToWW_Pt-200ToInf_M-125/outfiles/test/out.root\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "OUTPATH = \"../datafiles/TaggerInputFeb9_2017/\"     \n",
    "\n",
    "for sample in os.listdir(f\"{OUTPATH}\"):\n",
    "\n",
    "    if \"DS_Store\" in sample:\n",
    "        continue    \n",
    "    if \"run_skimmer\" in sample:\n",
    "        continue    \n",
    "    if \"inputprocessor\" in sample:\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(f\"{OUTPATH}/{sample}/outfiles//train/\"):\n",
    "        if \"root\" not in file:\n",
    "            continue\n",
    "        print(f\"Inspecting file {OUTPATH}/{sample}/outfiles/train/{file}\")\n",
    "        events = uproot.open(f\"{OUTPATH}/{sample}/outfiles/train/{file}\")[\"Events\"]\n",
    "\n",
    "        for var in events.keys():\n",
    "            nans = (np.isnan(events[var].array().to_numpy())).sum()\n",
    "            if nans != 0:\n",
    "                print(file, nans, f\"nan {var} values\")\n",
    "\n",
    "\n",
    "    for file in os.listdir(f\"{OUTPATH}/{sample}/outfiles/test/\"):\n",
    "        if \"root\" not in file:\n",
    "            continue\n",
    "        print(f\"Inspecting file {OUTPATH}/{sample}/outfiles/test/{file}\")                \n",
    "        events = uproot.open(f\"{OUTPATH}/{sample}/outfiles/test/{file}\")[\"Events\"]\n",
    "\n",
    "        for var in events.keys():\n",
    "            nans = (np.isnan(events[var].array().to_numpy())).sum()\n",
    "            if nans != 0:\n",
    "                print(file, nans, f\"nan {var} values\")\n",
    "\n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3203724",
   "metadata": {},
   "source": [
    "# Check Number of events in ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3023b5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GluGluHToWW_Pt-200ToInf_M-125 train 302203\n",
      "GluGluHToWW_Pt-200ToInf_M-125 test 201470\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"GluGluHToWW_Pt-200ToInf_M-125\",\n",
    "]\n",
    "\n",
    "\n",
    "OUTPATH = \"../datafiles/TaggerInputFeb9_2017/\"     \n",
    "\n",
    "num_events = {}\n",
    "\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    num = 0    \n",
    "    try:\n",
    "        events = uproot.open(f\"{OUTPATH}/{sample}/outfiles/train/out.root\")[\"Events\"]\n",
    "        num += events.num_entries\n",
    "    except:\n",
    "        continue\n",
    "    print(sample, \"train\", num)\n",
    "\n",
    "\n",
    "    num = 0    \n",
    "\n",
    "    try:\n",
    "        events = uproot.open(f\"{OUTPATH}/{sample}/outfiles/test/out.root\")[\"Events\"]\n",
    "        num += events.num_entries\n",
    "    except:\n",
    "        continue\n",
    "    print(sample, \"test\", num)\n",
    "    \n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d8991",
   "metadata": {},
   "source": [
    "# Check Number of events after selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ea43b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GluGluHToWW_Pt-200ToInf_M-125 train 302203\n",
      "GluGluHToWW_Pt-200ToInf_M-125 test 35245\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"GluGluHToWW_Pt-200ToInf_M-125\",\n",
    "]\n",
    "\n",
    "OUTPATH = \"../datafiles/TaggerInput/TaggerInputFeb9_2017\"\n",
    "\n",
    "num_events = {}\n",
    "\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    num = 0    \n",
    "\n",
    "    try:\n",
    "        events = uproot.open(f\"{OUTPATH}/{sample}/outfiles/train/out.root\")[\"Events\"]\n",
    "        ### put selection below\n",
    "#         selection1 = (events[\"lep_fj_dr\"].array()>0.03) & (events[\"lep_fj_dr\"].array()<0.8) & (events[\"n_bjets_T\"].array()==0)\n",
    "#         selection2 = ( (events[\"fj_genRes_mass\"].array()==125) & (events[\"lep_fj_dr\"].array()>0.03) & (events[\"lep_fj_dr\"].array()<0.8) & (events[\"fj_isHVV_Matched\"].array()==1) & (events[\"fj_lepinprongs\"].array()==1) & (events[\"fj_nquarks\"].array()==2) & ((events[\"fj_isHVV_elenuqq\"].array()==1) | (events[\"fj_isHVV_munuqq\"].array()==1)) ) | (events[\"fj_genRes_mass\"].array()!=125)\n",
    "\n",
    "\n",
    "        selection2 = events[\"fj_pt\"].array()>190\n",
    "        num += ak.sum(selection2)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "    print(sample, \"train\", num)\n",
    "\n",
    "\n",
    "    num = 0    \n",
    "\n",
    "    try:\n",
    "        events = uproot.open(f\"{OUTPATH}/{sample}/outfiles/test/out.root\")[\"Events\"]\n",
    "        ### put selection below\n",
    "        selection1 = (events[\"lep_fj_dr\"].array()>0.03) & (events[\"lep_fj_dr\"].array()<0.8) & (events[\"n_bjets_T\"].array()==0)\n",
    "        selection2 = ( (events[\"fj_genRes_mass\"].array()==125) & (events[\"lep_fj_dr\"].array()>0.03) & (events[\"lep_fj_dr\"].array()<0.8) & (events[\"fj_isHVV_Matched\"].array()==1) & (events[\"fj_lepinprongs\"].array()==1) & (events[\"fj_nquarks\"].array()==2) & ((events[\"fj_isHVV_elenuqq\"].array()==1) | (events[\"fj_isHVV_munuqq\"].array()==1)) ) | (events[\"fj_genRes_mass\"].array()!=125)\n",
    "\n",
    "        num += ak.sum(selection1 & selection2)\n",
    "    except:\n",
    "        continue\n",
    "    print(sample, \"test\", num)\n",
    "    \n",
    "    print(\"--------------------------\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ab14f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-env",
   "language": "python",
   "name": "coffea-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
