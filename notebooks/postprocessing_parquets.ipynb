{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cb702c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import uproot\n",
    "import glob\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1d8a1d30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datafiles/TaggerInput/TaggerInput_2016:\r\n",
      "\u001b[34mGluGluHToWW_Pt-200ToInf_M-125\u001b[m\u001b[m          \u001b[34mVBFHToWWToLNuQQ_M-125_withDipoleRecoil\u001b[m\u001b[m\r\n",
      "\r\n",
      "../datafiles/TaggerInput/TaggerInput_2016APV:\r\n",
      "\u001b[34mGluGluHToWW_Pt-200ToInf_M-125\u001b[m\u001b[m          \u001b[34mVBFHToWWToLNuQQ_M-125_withDipoleRecoil\u001b[m\u001b[m\r\n",
      "\r\n",
      "../datafiles/TaggerInput/TaggerInput_2017:\r\n",
      "\u001b[34mGluGluHToWW_Pt-200ToInf_M-125\u001b[m\u001b[m          \u001b[34mVBFHToWWToLNuQQ_M-125_withDipoleRecoil\u001b[m\u001b[m\r\n",
      "\r\n",
      "../datafiles/TaggerInput/TaggerInput_2018:\r\n",
      "\u001b[34mGluGluHToWW_Pt-200ToInf_M-125\u001b[m\u001b[m          \u001b[34mTTToSemiLeptonic\u001b[m\u001b[m\r\n",
      "\u001b[34mQCD_Pt_170to300\u001b[m\u001b[m                        \u001b[34mVBFHToWWToLNuQQ_M-125_withDipoleRecoil\u001b[m\u001b[m\r\n",
      "\u001b[34mQCD_Pt_300to470\u001b[m\u001b[m                        \u001b[34mWJetsToLNu_HT-200To400\u001b[m\u001b[m\r\n",
      "\u001b[34mQCD_Pt_470to600\u001b[m\u001b[m                        \u001b[34mWJetsToLNu_HT-400To600\u001b[m\u001b[m\r\n",
      "\u001b[34mQCD_Pt_600to800\u001b[m\u001b[m                        \u001b[34mWJetsToLNu_HT-600To800\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../datafiles/TaggerInput/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e749f7b",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3f37bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we must add the \"fj_isVBF\" & \"fj_isggF\" labels that we forgot to include in the processor\n",
    "def postprocess(df, sample):\n",
    "    if \"HToWW\" in sample:        \n",
    "        if \"VBF\" in sample:\n",
    "            df[\"fj_isggF\"] = 0\n",
    "            df[\"fj_isVBF\"] = 1\n",
    "        elif \"GluGluHToWW\" in sample:\n",
    "            df[\"fj_isggF\"] = 1\n",
    "            df[\"fj_isVBF\"] = 0      \n",
    "    else:\n",
    "        df[\"fj_isggF\"] = 0\n",
    "        df[\"fj_isVBF\"] = 0    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2b96bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "OUTPATH = \"../datafiles/TaggerInput/\"\n",
    "\n",
    "for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):\n",
    "    if \"DS_Store\" in dir_TaggerInput:\n",
    "        continue    \n",
    "\n",
    "    for sample in os.listdir(f\"{OUTPATH}/{dir_TaggerInput}\"):\n",
    "        if \"DS_Store\" in sample:\n",
    "            continue    \n",
    "        if \"run_skimmer\" in sample:\n",
    "            continue    \n",
    "        if \"inputprocessor\" in sample:\n",
    "            continue            \n",
    "\n",
    "        outdir = f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles\"        \n",
    "        df = pd.read_parquet(glob.glob(f\"{outdir}/*.parquet\"))\n",
    "        df = postprocess(df, sample)\n",
    "\n",
    "        df_train, df_test = sklearn.model_selection.train_test_split(df, test_size=0.4)\n",
    "\n",
    "        os.mkdir(f\"{outdir}/train\")\n",
    "        with uproot.recreate(f\"{outdir}/train/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "            rfile[\"Events\"] = ak.Array(df_train.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "        os.mkdir(f\"{outdir}/test\")            \n",
    "        with uproot.recreate(f\"{outdir}/test/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "            rfile[\"Events\"] = ak.Array(df_test.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "        print(\"--------------------------\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120ab7cf",
   "metadata": {},
   "source": [
    "# Convert parquets to root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "30bb494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "OUTPATH = \"../datafiles/ntuples/\"\n",
    "\n",
    "for sample in os.listdir(f\"{OUTPATH}/\"):\n",
    "    if \"DS_Store\" in sample:\n",
    "        continue    \n",
    "    if \"run_skimmer\" in sample:\n",
    "        continue    \n",
    "    if \"inputprocessor\" in sample:\n",
    "        continue            \n",
    "\n",
    "    for year in os.listdir(f\"{OUTPATH}/{sample}/\"):\n",
    "        \n",
    "        if \"DS_Store\" in year:\n",
    "            continue\n",
    "        \n",
    "        # train dataset\n",
    "        outdir = f\"{OUTPATH}/{sample}/{year}/train\"\n",
    "        df = pd.read_parquet(glob.glob(f\"{outdir}/*.parquet\"))\n",
    "\n",
    "        with uproot.recreate(f\"{outdir}/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "            rfile[\"Events\"] = ak.Array(df.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "        # test dataset\n",
    "        outdir = f\"{OUTPATH}/{sample}/{year}/test\"\n",
    "        df = pd.read_parquet(glob.glob(f\"{outdir}/*.parquet\"))\n",
    "\n",
    "        with uproot.recreate(f\"{outdir}/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "            rfile[\"Events\"] = ak.Array(df.to_dict(orient=\"list\", index=True))\n",
    "                             \n",
    "        print(\"--------------------------\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac405cc",
   "metadata": {},
   "source": [
    "# Inspecting NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b79b856e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/VBFHToWWToLNuQQ_M-125_withDipoleRecoil/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/VBFHToWWToLNuQQ_M-125_withDipoleRecoil/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/TTToSemiLeptonic/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/TTToSemiLeptonic/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/WJetsToLNu_HT-200To400/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/WJetsToLNu_HT-200To400/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/GluGluHToWW_Pt-200ToInf_M-125/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/GluGluHToWW_Pt-200ToInf_M-125/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_600to800/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_600to800/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_300to470/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_300to470/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_170to300/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_170to300/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/WJetsToLNu_HT-600To800/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/WJetsToLNu_HT-600To800/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/WJetsToLNu_HT-400To600/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/WJetsToLNu_HT-400To600/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_470to600/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_470to600/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2016/VBFHToWWToLNuQQ_M-125_withDipoleRecoil/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2016/VBFHToWWToLNuQQ_M-125_withDipoleRecoil/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2016/GluGluHToWW_Pt-200ToInf_M-125/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2016/GluGluHToWW_Pt-200ToInf_M-125/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2017/VBFHToWWToLNuQQ_M-125_withDipoleRecoil/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2017/VBFHToWWToLNuQQ_M-125_withDipoleRecoil/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2016APV/VBFHToWWToLNuQQ_M-125_withDipoleRecoil/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2016APV/VBFHToWWToLNuQQ_M-125_withDipoleRecoil/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2016APV/GluGluHToWW_Pt-200ToInf_M-125/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2016APV/GluGluHToWW_Pt-200ToInf_M-125/outfiles/test/out.root\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "OUTPATH = \"../datafiles/TaggerInput/\"\n",
    "\n",
    "for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):\n",
    "    if \"DS_Store\" in dir_TaggerInput:\n",
    "        continue    \n",
    "\n",
    "    for sample in os.listdir(f\"{OUTPATH}/{dir_TaggerInput}\"):\n",
    "        if \"DS_Store\" in sample:\n",
    "            continue    \n",
    "        if \"run_skimmer\" in sample:\n",
    "            continue    \n",
    "        if \"inputprocessor\" in sample:\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles//train/\"):\n",
    "            if \"root\" not in file:\n",
    "                continue\n",
    "            print(f\"Inspecting file {OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/train/{file}\")\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/train/{file}\")[\"Events\"]\n",
    "\n",
    "            for var in events.keys():\n",
    "                nans = (np.isnan(events[var].array().to_numpy())).sum()\n",
    "                if nans != 0:\n",
    "                    print(file, nans, f\"nan {var} values\")\n",
    "\n",
    "\n",
    "        for file in os.listdir(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/\"):\n",
    "            if \"root\" not in file:\n",
    "                continue\n",
    "            print(f\"Inspecting file {OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/{file}\")                \n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/{file}\")[\"Events\"]\n",
    "\n",
    "            for var in events.keys():\n",
    "                nans = (np.isnan(events[var].array().to_numpy())).sum()\n",
    "                if nans != 0:\n",
    "                    print(file, nans, f\"nan {var} values\")\n",
    "\n",
    "        print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3203724",
   "metadata": {},
   "source": [
    "# Check Number of events in ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d3023b5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GluGluHToWW_Pt-200ToInf_M-125 train 230992\n",
      "GluGluHToWW_Pt-200ToInf_M-125 test 153996\n",
      "--------------------------\n",
      "TTToSemiLeptonic train 1013771\n",
      "TTToSemiLeptonic test 675848\n",
      "--------------------------\n",
      "WJetsToLNu_HT-200To400 train 403144\n",
      "WJetsToLNu_HT-200To400 test 268764\n",
      "--------------------------\n",
      "WJetsToLNu_HT-400To600 train 780325\n",
      "WJetsToLNu_HT-400To600 test 520218\n",
      "--------------------------\n",
      "WJetsToLNu_HT-600To800 train 547966\n",
      "WJetsToLNu_HT-600To800 test 365312\n",
      "--------------------------\n",
      "QCD_Pt_170to300 train 496477\n",
      "QCD_Pt_170to300 test 330986\n",
      "--------------------------\n",
      "QCD_Pt_300to470 train 593239\n",
      "QCD_Pt_300to470 test 395494\n",
      "--------------------------\n",
      "QCD_Pt_470to600 train 1098982\n",
      "QCD_Pt_470to600 test 732655\n",
      "--------------------------\n",
      "QCD_Pt_600to800 train 203296\n",
      "QCD_Pt_600to800 test 135532\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"GluGluHToWW_Pt-200ToInf_M-125\",\n",
    "    \"TTToSemiLeptonic\",\n",
    "    \"WJetsToLNu_HT-200To400\",\n",
    "    \"WJetsToLNu_HT-400To600\",\n",
    "    \"WJetsToLNu_HT-600To800\",\n",
    "    \"QCD_Pt_170to300\",\n",
    "    \"QCD_Pt_300to470\",\n",
    "    \"QCD_Pt_470to600\",\n",
    "    \"QCD_Pt_600to800\",\n",
    "]\n",
    "\n",
    "OUTPATH = \"../datafiles/TaggerInput/\"\n",
    "\n",
    "num_events = {}\n",
    "\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue    \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/train/out.root\")[\"Events\"]\n",
    "            num += events.num_entries\n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"train\", num)\n",
    "\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue    \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/out.root\")[\"Events\"]\n",
    "            num += events.num_entries\n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"test\", num)\n",
    "    \n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d8991",
   "metadata": {},
   "source": [
    "# Check Number of events after selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2ea43b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GluGluHToWW_Pt-200ToInf_M-125 train 56305\n",
      "GluGluHToWW_Pt-200ToInf_M-125 test 37348\n",
      "--------------------------\n",
      "TTToSemiLeptonic train 213367\n",
      "TTToSemiLeptonic test 141642\n",
      "--------------------------\n",
      "WJetsToLNu_HT-200To400 train 38310\n",
      "WJetsToLNu_HT-200To400 test 25504\n",
      "--------------------------\n",
      "WJetsToLNu_HT-400To600 train 176549\n",
      "WJetsToLNu_HT-400To600 test 117179\n",
      "--------------------------\n",
      "WJetsToLNu_HT-600To800 train 238595\n",
      "WJetsToLNu_HT-600To800 test 158614\n",
      "--------------------------\n",
      "QCD_Pt_170to300 train 57234\n",
      "QCD_Pt_170to300 test 38501\n",
      "--------------------------\n",
      "QCD_Pt_300to470 train 329364\n",
      "QCD_Pt_300to470 test 219841\n",
      "--------------------------\n",
      "QCD_Pt_470to600 train 66515\n",
      "QCD_Pt_470to600 test 44313\n",
      "--------------------------\n",
      "QCD_Pt_600to800 train 5362\n",
      "QCD_Pt_600to800 test 3647\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"GluGluHToWW_Pt-200ToInf_M-125\",\n",
    "    \"TTToSemiLeptonic\",\n",
    "    \"WJetsToLNu_HT-200To400\",\n",
    "    \"WJetsToLNu_HT-400To600\",\n",
    "    \"WJetsToLNu_HT-600To800\",\n",
    "    \"QCD_Pt_170to300\",\n",
    "    \"QCD_Pt_300to470\",\n",
    "    \"QCD_Pt_470to600\",\n",
    "    \"QCD_Pt_600to800\",\n",
    "]\n",
    "\n",
    "OUTPATH = \"../datafiles/TaggerInput/\"\n",
    "\n",
    "num_events = {}\n",
    "\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue    \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/train/out.root\")[\"Events\"]\n",
    "            ### put selection below\n",
    "            selection = (events[\"fj_pt\"].array()>300) & (events[\"fj_pt\"].array()<400)\n",
    "            num += ak.sum(selection)\n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"train\", num)\n",
    "\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue    \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/out.root\")[\"Events\"]\n",
    "            ### put selection below\n",
    "            selection = (events[\"fj_pt\"].array()>300) & (events[\"fj_pt\"].array()<400)\n",
    "            num += ak.sum(selection)\n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"test\", num)\n",
    "    \n",
    "    print(\"--------------------------\")        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-env",
   "language": "python",
   "name": "coffea-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
