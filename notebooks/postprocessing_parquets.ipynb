{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb702c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import uproot\n",
    "import glob\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97653d40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTaggerInputFeb9_2017\u001b[m\u001b[m \u001b[34mTaggerInput_2016APV\u001b[m\u001b[m  \u001b[34mTaggerInput_2018\u001b[m\u001b[m\r\n",
      "\u001b[34mTaggerInput_2016\u001b[m\u001b[m     \u001b[34mTaggerInput_2017\u001b[m\u001b[m     \u001b[34mremove\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../datafiles/TaggerInput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e749f7b",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f37bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_vars(df):\n",
    "    \n",
    "    df = df.rename(columns={\n",
    "        \"mt_lep_met\": \"lep_met_mt\", \n",
    "        \"lep_dR_fj\": \"lep_fj_dr\",\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# we must add the \"fj_isVBF\" & \"fj_isggF\" labels that we forgot to include in the processor\n",
    "def postprocess(df, sample):\n",
    "    if \"HToWW\" in sample:        \n",
    "        if \"VBF\" in sample:\n",
    "            df[\"fj_isggF\"] = 0\n",
    "            df[\"fj_isVBF\"] = 1\n",
    "        elif \"GluGluHToWW\" in sample:\n",
    "            df[\"fj_isggF\"] = 1\n",
    "            df[\"fj_isVBF\"] = 0      \n",
    "    else:\n",
    "        df[\"fj_isggF\"] = 0\n",
    "        df[\"fj_isVBF\"] = 0  \n",
    "\n",
    "    df = rename_vars(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1b062d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls ../datafiles/new/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f0f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1353874b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing WJetsToLNu_2J\n",
      "making train directory\n",
      "making test directory\n",
      "--------------------------\n",
      "Processing WJetsToLNu_1J\n",
      "making train directory\n",
      "making test directory\n",
      "--------------------------\n",
      "Processing JHUVariableWMass_part3\n",
      "making train directory\n",
      "making test directory\n",
      "--------------------------\n",
      "Processing JHUVariableWMass_part2\n",
      "making train directory\n",
      "making test directory\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "OUTPATH = \"../datafiles/new/\"\n",
    "\n",
    "for sample in os.listdir(OUTPATH):\n",
    "    if \"DS_Store\" in sample:\n",
    "        continue\n",
    "            \n",
    "    print(f\"Processing {sample}\")\n",
    "\n",
    "    outdir = f\"{OUTPATH}/{sample}/outfiles/\"        \n",
    "    df = pd.read_parquet(f\"{outdir}/out.parquet\")\n",
    "    df.drop(columns=[\"fj_genH_pt\"], inplace=True)\n",
    "\n",
    "    df_train, df_test = sklearn.model_selection.train_test_split(df, test_size=0.4)\n",
    "\n",
    "    print(\"making train directory\")\n",
    "    os.system(f\"mkdir -p {outdir}/train\")\n",
    "    with uproot.recreate(f\"{outdir}/train/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "        rfile[\"Events\"] = ak.Array(df_train.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "    print(\"making test directory\")        \n",
    "    os.system(f\"mkdir -p {outdir}/test\")            \n",
    "    with uproot.recreate(f\"{outdir}/test/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "        rfile[\"Events\"] = ak.Array(df_test.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "    print(\"--------------------------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e48550",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b795dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"fj_genH_jet\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8bd6535",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fj_genH_jet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/coffea-env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fj_genH_jet'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfj_genH_jet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/coffea-env/lib/python3.9/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/coffea-env/lib/python3.9/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fj_genH_jet'"
     ]
    }
   ],
   "source": [
    "df[\"fj_genH_jet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4058920e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b96bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TTToSemiLeptonic from TaggerInput_2018\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'postprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m outdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_TaggerInput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/outfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m        \n\u001b[1;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/*.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 19\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpostprocess\u001b[49m(df, sample)\n\u001b[1;32m     21\u001b[0m df_train, df_test \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmodel_selection\u001b[38;5;241m.\u001b[39mtrain_test_split(df, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m)\n\u001b[1;32m     23\u001b[0m os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmkdir -p \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'postprocess' is not defined"
     ]
    }
   ],
   "source": [
    "OUTPATH = \"../datafiles/TaggerInput/\"\n",
    "\n",
    "for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):\n",
    "    if \"DS_Store\" in dir_TaggerInput:\n",
    "        continue    \n",
    "\n",
    "    for sample in os.listdir(f\"{OUTPATH}/{dir_TaggerInput}\"):\n",
    "        if \"DS_Store\" in sample:\n",
    "            continue    \n",
    "        if \"run_skimmer\" in sample:\n",
    "            continue    \n",
    "        if \"inputprocessor\" in sample:\n",
    "            continue            \n",
    "\n",
    "        print(f\"Processing {sample} from {dir_TaggerInput}\")\n",
    "            \n",
    "        outdir = f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles\"        \n",
    "        df = pd.read_parquet(glob.glob(f\"{outdir}/*.parquet\"))\n",
    "        df = postprocess(df, sample)\n",
    "\n",
    "        df_train, df_test = sklearn.model_selection.train_test_split(df, test_size=0.4)\n",
    "\n",
    "        os.system(f\"mkdir -p {outdir}/train\")\n",
    "        with uproot.recreate(f\"{outdir}/train/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "            rfile[\"Events\"] = ak.Array(df_train.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "        os.system(f\"mkdir -p {outdir}/test\")            \n",
    "        with uproot.recreate(f\"{outdir}/test/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "            rfile[\"Events\"] = ak.Array(df_test.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "        print(\"--------------------------\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120ab7cf",
   "metadata": {},
   "source": [
    "# Convert parquets to root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "30bb494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "OUTPATH = \"../datafiles/ntuples/\"\n",
    "\n",
    "for sample in os.listdir(f\"{OUTPATH}/\"):\n",
    "    if \"DS_Store\" in sample:\n",
    "        continue    \n",
    "    if \"run_skimmer\" in sample:\n",
    "        continue    \n",
    "    if \"inputprocessor\" in sample:\n",
    "        continue            \n",
    "\n",
    "    for year in os.listdir(f\"{OUTPATH}/{sample}/\"):\n",
    "        \n",
    "        if \"DS_Store\" in year:\n",
    "            continue\n",
    "        \n",
    "        # train dataset\n",
    "        outdir = f\"{OUTPATH}/{sample}/{year}/train\"\n",
    "        df = pd.read_parquet(glob.glob(f\"{outdir}/*.parquet\"))\n",
    "\n",
    "        with uproot.recreate(f\"{outdir}/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "            rfile[\"Events\"] = ak.Array(df.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "        # test dataset\n",
    "        outdir = f\"{OUTPATH}/{sample}/{year}/test\"\n",
    "        df = pd.read_parquet(glob.glob(f\"{outdir}/*.parquet\"))\n",
    "\n",
    "        with uproot.recreate(f\"{outdir}/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "            rfile[\"Events\"] = ak.Array(df.to_dict(orient=\"list\", index=True))\n",
    "                             \n",
    "        print(\"--------------------------\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "164499e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fj_eta\n",
      "fj_phi\n",
      "fj_mass\n",
      "fj_pt\n",
      "fj_msoftdrop\n",
      "fj_lsf3\n",
      "fj_genjetmass\n",
      "fj_genRes_pt\n",
      "fj_genRes_eta\n",
      "fj_genRes_phi\n",
      "fj_genRes_mass\n",
      "fj_genH_pt\n",
      "fj_genH_jet\n",
      "fj_genV_dR\n",
      "fj_genVstar\n",
      "genV_genVstar_dR\n",
      "fj_isHVV\n",
      "fj_isHVV_Matched\n",
      "fj_isHVV_4q\n",
      "fj_isHVV_elenuqq\n",
      "fj_isHVV_munuqq\n",
      "fj_isHVV_taunuqq\n",
      "fj_isHVV_Vlepton\n",
      "fj_isHVV_Vstarlepton\n",
      "fj_nquarks\n",
      "fj_lepinprongs\n",
      "fj_isV\n",
      "fj_isV_Matched\n",
      "fj_isV_2q\n",
      "fj_isV_elenu\n",
      "fj_isV_munu\n",
      "fj_isV_taunu\n",
      "fj_nprongs\n",
      "fj_ncquarks\n",
      "fj_isV_lep\n",
      "fj_isTop\n",
      "fj_isTop_Matched\n",
      "fj_Top_numMatched\n",
      "fj_isTop_W_lep_b\n",
      "fj_isTop_W_lep\n",
      "fj_isTop_W_ele_b\n",
      "fj_isTop_W_ele\n",
      "fj_isTop_W_mu_b\n",
      "fj_isTop_W_mu\n",
      "fj_isTop_W_tau_b\n",
      "fj_isTop_W_tau\n",
      "fj_Top_nquarksnob\n",
      "fj_Top_nbquarks\n",
      "fj_Top_ncquarks\n",
      "fj_Top_nleptons\n",
      "fj_Top_nele\n",
      "fj_Top_nmu\n",
      "fj_Top_ntau\n",
      "fj_Top_taudecay\n",
      "fj_isQCD\n",
      "fj_isQCD_Matched\n",
      "fj_isQCDb\n",
      "fj_isQCDbb\n",
      "fj_isQCDc\n",
      "fj_isQCDcc\n",
      "fj_isQCDothers\n",
      "met_pt\n",
      "met_relpt\n",
      "met_fj_dphi\n",
      "abs_met_fj_dphi\n",
      "mt_lep_met\n",
      "lep_dR_fj\n",
      "lep_pt\n",
      "lep_pt_ratio\n",
      "lep_reliso\n",
      "lep_miso\n",
      "n_bjets_L\n",
      "n_bjets_M\n",
      "n_bjets_T\n",
      "rec_W_lnu_pt\n",
      "rec_W_lnu_m\n",
      "rec_W_qq_pt\n",
      "rec_W_qq_m\n",
      "rec_higgs_pt\n",
      "rec_higgs_m\n",
      "mjj\n",
      "jj_pt\n",
      "deta\n",
      "j1_pt\n",
      "j2_pt\n",
      "j1_m\n",
      "j2_m\n",
      "ht\n",
      "NumFatjets\n",
      "NumOtherJets\n",
      "FirstFatjet_pt\n",
      "FirstFatjet_m\n",
      "SecondFatjet_pt\n",
      "SecondFatjet_m\n",
      "fj_ParT_score\n",
      "fj_ParT_mass\n",
      "fj_ParT_hidNeuron000\n",
      "fj_ParT_hidNeuron001\n",
      "fj_ParT_hidNeuron002\n",
      "fj_ParT_hidNeuron003\n",
      "fj_ParT_hidNeuron004\n",
      "fj_ParT_hidNeuron005\n",
      "fj_ParT_hidNeuron006\n",
      "fj_ParT_hidNeuron007\n",
      "fj_ParT_hidNeuron008\n",
      "fj_ParT_hidNeuron009\n",
      "fj_ParT_hidNeuron010\n",
      "fj_ParT_hidNeuron011\n",
      "fj_ParT_hidNeuron012\n",
      "fj_ParT_hidNeuron013\n",
      "fj_ParT_hidNeuron014\n",
      "fj_ParT_hidNeuron015\n",
      "fj_ParT_hidNeuron016\n",
      "fj_ParT_hidNeuron017\n",
      "fj_ParT_hidNeuron018\n",
      "fj_ParT_hidNeuron019\n",
      "fj_ParT_hidNeuron020\n",
      "fj_ParT_hidNeuron021\n",
      "fj_ParT_hidNeuron022\n",
      "fj_ParT_hidNeuron023\n",
      "fj_ParT_hidNeuron024\n",
      "fj_ParT_hidNeuron025\n",
      "fj_ParT_hidNeuron026\n",
      "fj_ParT_hidNeuron027\n",
      "fj_ParT_hidNeuron028\n",
      "fj_ParT_hidNeuron029\n",
      "fj_ParT_hidNeuron030\n",
      "fj_ParT_hidNeuron031\n",
      "fj_ParT_hidNeuron032\n",
      "fj_ParT_hidNeuron033\n",
      "fj_ParT_hidNeuron034\n",
      "fj_ParT_hidNeuron035\n",
      "fj_ParT_hidNeuron036\n",
      "fj_ParT_hidNeuron037\n",
      "fj_ParT_hidNeuron038\n",
      "fj_ParT_hidNeuron039\n",
      "fj_ParT_hidNeuron040\n",
      "fj_ParT_hidNeuron041\n",
      "fj_ParT_hidNeuron042\n",
      "fj_ParT_hidNeuron043\n",
      "fj_ParT_hidNeuron044\n",
      "fj_ParT_hidNeuron045\n",
      "fj_ParT_hidNeuron046\n",
      "fj_ParT_hidNeuron047\n",
      "fj_ParT_hidNeuron048\n",
      "fj_ParT_hidNeuron049\n",
      "fj_ParT_hidNeuron050\n",
      "fj_ParT_hidNeuron051\n",
      "fj_ParT_hidNeuron052\n",
      "fj_ParT_hidNeuron053\n",
      "fj_ParT_hidNeuron054\n",
      "fj_ParT_hidNeuron055\n",
      "fj_ParT_hidNeuron056\n",
      "fj_ParT_hidNeuron057\n",
      "fj_ParT_hidNeuron058\n",
      "fj_ParT_hidNeuron059\n",
      "fj_ParT_hidNeuron060\n",
      "fj_ParT_hidNeuron061\n",
      "fj_ParT_hidNeuron062\n",
      "fj_ParT_hidNeuron063\n",
      "fj_ParT_hidNeuron064\n",
      "fj_ParT_hidNeuron065\n",
      "fj_ParT_hidNeuron066\n",
      "fj_ParT_hidNeuron067\n",
      "fj_ParT_hidNeuron068\n",
      "fj_ParT_hidNeuron069\n",
      "fj_ParT_hidNeuron070\n",
      "fj_ParT_hidNeuron071\n",
      "fj_ParT_hidNeuron072\n",
      "fj_ParT_hidNeuron073\n",
      "fj_ParT_hidNeuron074\n",
      "fj_ParT_hidNeuron075\n",
      "fj_ParT_hidNeuron076\n",
      "fj_ParT_hidNeuron077\n",
      "fj_ParT_hidNeuron078\n",
      "fj_ParT_hidNeuron079\n",
      "fj_ParT_hidNeuron080\n",
      "fj_ParT_hidNeuron081\n",
      "fj_ParT_hidNeuron082\n",
      "fj_ParT_hidNeuron083\n",
      "fj_ParT_hidNeuron084\n",
      "fj_ParT_hidNeuron085\n",
      "fj_ParT_hidNeuron086\n",
      "fj_ParT_hidNeuron087\n",
      "fj_ParT_hidNeuron088\n",
      "fj_ParT_hidNeuron089\n",
      "fj_ParT_hidNeuron090\n",
      "fj_ParT_hidNeuron091\n",
      "fj_ParT_hidNeuron092\n",
      "fj_ParT_hidNeuron093\n",
      "fj_ParT_hidNeuron094\n",
      "fj_ParT_hidNeuron095\n",
      "fj_ParT_hidNeuron096\n",
      "fj_ParT_hidNeuron097\n",
      "fj_ParT_hidNeuron098\n",
      "fj_ParT_hidNeuron099\n",
      "fj_ParT_hidNeuron100\n",
      "fj_ParT_hidNeuron101\n",
      "fj_ParT_hidNeuron102\n",
      "fj_ParT_hidNeuron103\n",
      "fj_ParT_hidNeuron104\n",
      "fj_ParT_hidNeuron105\n",
      "fj_ParT_hidNeuron106\n",
      "fj_ParT_hidNeuron107\n",
      "fj_ParT_hidNeuron108\n",
      "fj_ParT_hidNeuron109\n",
      "fj_ParT_hidNeuron110\n",
      "fj_ParT_hidNeuron111\n",
      "fj_ParT_hidNeuron112\n",
      "fj_ParT_hidNeuron113\n",
      "fj_ParT_hidNeuron114\n",
      "fj_ParT_hidNeuron115\n",
      "fj_ParT_hidNeuron116\n",
      "fj_ParT_hidNeuron117\n",
      "fj_ParT_hidNeuron118\n",
      "fj_ParT_hidNeuron119\n",
      "fj_ParT_hidNeuron120\n",
      "fj_ParT_hidNeuron121\n",
      "fj_ParT_hidNeuron122\n",
      "fj_ParT_hidNeuron123\n",
      "fj_ParT_hidNeuron124\n",
      "fj_ParT_hidNeuron125\n",
      "fj_ParT_hidNeuron126\n",
      "fj_ParT_hidNeuron127\n",
      "fj_isggF\n",
      "fj_isVBF\n"
     ]
    }
   ],
   "source": [
    "for key in df:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac405cc",
   "metadata": {},
   "source": [
    "# Inspecting NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b79b856e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/TTToSemiLeptonic/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/TTToSemiLeptonic/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/WJetsToLNu_2J/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/WJetsToLNu_2J/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/WJetsToLNu_1J/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/WJetsToLNu_1J/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_600to800/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_600to800/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_300to470/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_300to470/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_170to300/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_170to300/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_470to600/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2018/QCD_Pt_470to600/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2017/JHUVariableWMass_part1/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2017/JHUVariableWMass_part1/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2017/JHUVariableWMass_part3/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2017/JHUVariableWMass_part3/outfiles/test/out.root\n",
      "--------------------------\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2017/JHUVariableWMass_part2/outfiles/train/out.root\n",
      "Inspecting file ../datafiles/TaggerInput//TaggerInput_2017/JHUVariableWMass_part2/outfiles/test/out.root\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "OUTPATH = \"../datafiles/TaggerInput/\"\n",
    "\n",
    "for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):\n",
    "    if \"DS_Store\" in dir_TaggerInput:\n",
    "        continue\n",
    "    if \"remove\" in dir_TaggerInput:\n",
    "        continue        \n",
    "\n",
    "    for sample in os.listdir(f\"{OUTPATH}/{dir_TaggerInput}\"):\n",
    "\n",
    "        if \"DS_Store\" in sample:\n",
    "            continue    \n",
    "        if \"run_skimmer\" in sample:\n",
    "            continue    \n",
    "        if \"inputprocessor\" in sample:\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles//train/\"):\n",
    "            if \"root\" not in file:\n",
    "                continue\n",
    "            print(f\"Inspecting file {OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/train/{file}\")\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/train/{file}\")[\"Events\"]\n",
    "\n",
    "            for var in events.keys():\n",
    "                nans = (np.isnan(events[var].array().to_numpy())).sum()\n",
    "                if nans != 0:\n",
    "                    print(file, nans, f\"nan {var} values\")\n",
    "\n",
    "\n",
    "        for file in os.listdir(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/\"):\n",
    "            if \"root\" not in file:\n",
    "                continue\n",
    "            print(f\"Inspecting file {OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/{file}\")                \n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/{file}\")[\"Events\"]\n",
    "\n",
    "            for var in events.keys():\n",
    "                nans = (np.isnan(events[var].array().to_numpy())).sum()\n",
    "                if nans != 0:\n",
    "                    print(file, nans, f\"nan {var} values\")\n",
    "\n",
    "        print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fcd792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0b6ce48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mJHUVariableWMass_part1\u001b[m\u001b[m \u001b[34mJHUVariableWMass_part2\u001b[m\u001b[m \u001b[34mJHUVariableWMass_part3\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../datafiles/TaggerInput/TaggerInput_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3203724",
   "metadata": {},
   "source": [
    "# Check Number of events in ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3023b5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GluGluHToWW_Pt-200ToInf_M-125 train 58345\n",
      "GluGluHToWW_Pt-200ToInf_M-125 test 38898\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"GluGluHToWW_Pt-200ToInf_M-125\",\n",
    "#     \"VBFHToWWToLNuQQ_M-125_withDipoleRecoil\",\n",
    "#     \"JHUVariableWMass_part1\",\n",
    "#     \"JHUVariableWMass_part2\",\n",
    "#     \"JHUVariableWMass_part3\",    \n",
    "#     \"TTToSemiLeptonic\",\n",
    "#     \"WJetsToLNu_1J\",\n",
    "#     \"WJetsToLNu_2J\",    \n",
    "#     \"WJetsToLNu_HT-200To400\",\n",
    "#     \"WJetsToLNu_HT-400To600\",\n",
    "#     \"WJetsToLNu_HT-600To800\",\n",
    "#     \"QCD_Pt_170to300\",\n",
    "#     \"QCD_Pt_300to470\",\n",
    "#     \"QCD_Pt_470to600\",\n",
    "#     \"QCD_Pt_600to800\",\n",
    "]\n",
    "\n",
    "\n",
    "OUTPATH = \"../datafiles/TaggerInput/\"\n",
    "\n",
    "num_events = {}\n",
    "\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue    \n",
    "        if \"remove\" in dir_TaggerInput:\n",
    "            continue            \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/train/out.root\")[\"Events\"]\n",
    "            num += events.num_entries\n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"train\", num)\n",
    "\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue    \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/out.root\")[\"Events\"]\n",
    "            num += events.num_entries\n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"test\", num)\n",
    "    \n",
    "    print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d8991",
   "metadata": {},
   "source": [
    "# Check Number of events after selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b09454",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GluGluHToWW_Pt-200ToInf_M-125 train 56005\n",
      "GluGluHToWW_Pt-200ToInf_M-125 test 37342\n",
      "--------------------------\n",
      "TTToSemiLeptonic train 794799\n",
      "TTToSemiLeptonic test 529868\n",
      "--------------------------\n",
      "WJetsToLNu_HT-200To400 train 130212\n",
      "WJetsToLNu_HT-200To400 test 86852\n",
      "--------------------------\n",
      "WJetsToLNu_HT-400To600 train 393385\n",
      "WJetsToLNu_HT-400To600 test 262543\n",
      "--------------------------\n",
      "WJetsToLNu_HT-600To800 train 296645\n",
      "WJetsToLNu_HT-600To800 test 197694\n",
      "--------------------------\n",
      "QCD_Pt_170to300 train 257404\n",
      "QCD_Pt_170to300 test 171220\n",
      "--------------------------\n",
      "QCD_Pt_300to470 train 301000\n",
      "QCD_Pt_300to470 test 200713\n",
      "--------------------------\n",
      "QCD_Pt_470to600 train 532099\n",
      "QCD_Pt_470to600 test 354596\n",
      "--------------------------\n",
      "QCD_Pt_600to800 train 94978\n",
      "QCD_Pt_600to800 test 63220\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"GluGluHToWW_Pt-200ToInf_M-125\",    \n",
    "#     \"VBFHToWWToLNuQQ_M-125_withDipoleRecoil\",\n",
    "#     \"JHUVariableWMass_part1\",\n",
    "#     \"JHUVariableWMass_part2\",\n",
    "#     \"JHUVariableWMass_part3\",    \n",
    "    \"TTToSemiLeptonic\",\n",
    "#     \"WJetsToLNu_1J\",\n",
    "#     \"WJetsToLNu_2J\",    \n",
    "    \"WJetsToLNu_HT-200To400\",\n",
    "    \"WJetsToLNu_HT-400To600\",\n",
    "    \"WJetsToLNu_HT-600To800\",\n",
    "    \"QCD_Pt_170to300\",\n",
    "    \"QCD_Pt_300to470\",\n",
    "    \"QCD_Pt_470to600\",\n",
    "    \"QCD_Pt_600to800\",\n",
    "]\n",
    "\n",
    "OUTPATH = \"../datafiles/TaggerInput/\"\n",
    "\n",
    "num_events = {}\n",
    "\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue \n",
    "            \n",
    "        if \"remove\" in dir_TaggerInput:\n",
    "            continue             \n",
    "                        \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/train/out.root\")[\"Events\"]\n",
    "            ### put selection below\n",
    "            selection1 = (events[\"lep_fj_dr\"].array()>0.03) & (events[\"lep_fj_dr\"].array()<0.8)\n",
    "            selection2 = ( (events[\"fj_genRes_mass\"].array()==125) & (events[\"fj_isHVV_Matched\"].array()==1) & (events[\"fj_lepinprongs\"].array()==1) & (events[\"fj_nquarks\"].array()==2) & ((events[\"fj_isHVV_elenuqq\"].array()==1) | (events[\"fj_isHVV_munuqq\"].array()==1)) ) | (events[\"fj_genRes_mass\"].array()!=125)\n",
    "                    \n",
    "            num += ak.sum(selection1 & selection2)\n",
    "\n",
    "        except:\n",
    "#             print(\"no file found for\", f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles\")\n",
    "            continue\n",
    "    print(sample, \"train\", num)\n",
    "\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue   \n",
    "        if \"remove\" in dir_TaggerInput:\n",
    "            continue                         \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/out.root\")[\"Events\"]\n",
    "            ### put selection below\n",
    "            selection1 = (events[\"lep_fj_dr\"].array()>0.03) & (events[\"lep_fj_dr\"].array()<0.8)\n",
    "            selection2 = ( (events[\"fj_genRes_mass\"].array()==125) & (events[\"fj_isHVV_Matched\"].array()==1) & (events[\"fj_lepinprongs\"].array()==1) & (events[\"fj_nquarks\"].array()==2) & ((events[\"fj_isHVV_elenuqq\"].array()==1) | (events[\"fj_isHVV_munuqq\"].array()==1)) ) | (events[\"fj_genRes_mass\"].array()!=125)\n",
    "            \n",
    "            num += ak.sum(selection1 & selection2)\n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"test\", num)\n",
    "    \n",
    "    print(\"--------------------------\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aad5483d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.root\r\n"
     ]
    }
   ],
   "source": [
    "! ls  \"../datafiles/TaggerInput/TaggerInputFeb9_2017/GluGluHToWW_Pt-200ToInf_M-125/outfiles/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ea43b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GluGluHToWW_Pt-200ToInf_M-125 train 56005\n",
      "GluGluHToWW_Pt-200ToInf_M-125 test 37342\n",
      "--------------------------\n",
      "TTToSemiLeptonic train 794799\n",
      "TTToSemiLeptonic test 529868\n",
      "--------------------------\n",
      "WJetsToLNu_HT-200To400 train 130212\n",
      "WJetsToLNu_HT-200To400 test 86852\n",
      "--------------------------\n",
      "WJetsToLNu_HT-400To600 train 393385\n",
      "WJetsToLNu_HT-400To600 test 262543\n",
      "--------------------------\n",
      "WJetsToLNu_HT-600To800 train 296645\n",
      "WJetsToLNu_HT-600To800 test 197694\n",
      "--------------------------\n",
      "QCD_Pt_170to300 train 257404\n",
      "QCD_Pt_170to300 test 171220\n",
      "--------------------------\n",
      "QCD_Pt_300to470 train 301000\n",
      "QCD_Pt_300to470 test 200713\n",
      "--------------------------\n",
      "QCD_Pt_470to600 train 532099\n",
      "QCD_Pt_470to600 test 354596\n",
      "--------------------------\n",
      "QCD_Pt_600to800 train 94978\n",
      "QCD_Pt_600to800 test 63220\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"GluGluHToWW_Pt-200ToInf_M-125\",    \n",
    "#     \"VBFHToWWToLNuQQ_M-125_withDipoleRecoil\",\n",
    "#     \"JHUVariableWMass_part1\",\n",
    "#     \"JHUVariableWMass_part2\",\n",
    "#     \"JHUVariableWMass_part3\",    \n",
    "    \"TTToSemiLeptonic\",\n",
    "#     \"WJetsToLNu_1J\",\n",
    "#     \"WJetsToLNu_2J\",    \n",
    "    \"WJetsToLNu_HT-200To400\",\n",
    "    \"WJetsToLNu_HT-400To600\",\n",
    "    \"WJetsToLNu_HT-600To800\",\n",
    "    \"QCD_Pt_170to300\",\n",
    "    \"QCD_Pt_300to470\",\n",
    "    \"QCD_Pt_470to600\",\n",
    "    \"QCD_Pt_600to800\",\n",
    "]\n",
    "\n",
    "OUTPATH = \"../datafiles/TaggerInput/\"\n",
    "\n",
    "num_events = {}\n",
    "\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue \n",
    "            \n",
    "        if \"rm_\" in dir_TaggerInput:\n",
    "            continue             \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/train/out.root\")[\"Events\"]\n",
    "            ### put selection below\n",
    "            selection1 = (events[\"lep_fj_dr\"].array()>0.03) & (events[\"lep_fj_dr\"].array()<0.8)\n",
    "            selection2 = ( (events[\"fj_genRes_mass\"].array()==125) & (events[\"fj_isHVV_Matched\"].array()==1) & (events[\"fj_lepinprongs\"].array()==1) & (events[\"fj_nquarks\"].array()==2) & ((events[\"fj_isHVV_elenuqq\"].array()==1) | (events[\"fj_isHVV_munuqq\"].array()==1)) ) | (events[\"fj_genRes_mass\"].array()!=125)\n",
    "                    \n",
    "            num += ak.sum(selection1 & selection2)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"train\", num)\n",
    "\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue   \n",
    "        if \"rm_\" in dir_TaggerInput:\n",
    "            continue                         \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/out.root\")[\"Events\"]\n",
    "            ### put selection below\n",
    "            selection1 = (events[\"lep_fj_dr\"].array()>0.03) & (events[\"lep_fj_dr\"].array()<0.8)\n",
    "            selection2 = ( (events[\"fj_genRes_mass\"].array()==125) & (events[\"fj_isHVV_Matched\"].array()==1) & (events[\"fj_lepinprongs\"].array()==1) & (events[\"fj_nquarks\"].array()==2) & ((events[\"fj_isHVV_elenuqq\"].array()==1) | (events[\"fj_isHVV_munuqq\"].array()==1)) ) | (events[\"fj_genRes_mass\"].array()!=125)\n",
    "            \n",
    "            num += ak.sum(selection1 & selection2)\n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"test\", num)\n",
    "    \n",
    "    print(\"--------------------------\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb94eb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-env",
   "language": "python",
   "name": "coffea-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
