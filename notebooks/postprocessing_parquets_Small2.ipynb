{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb702c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import uproot\n",
    "import glob\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97653d40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTaggerInputMar26_2017\u001b[m\u001b[m \u001b[34mTaggerInput_2018\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../datafiles/TaggerInput_Small2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e749f7b",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f37bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_vars(df):\n",
    "    \n",
    "    df = df.rename(columns={\n",
    "        \"mt_lep_met\": \"lep_met_mt\", \n",
    "        \"lep_dR_fj\": \"lep_fj_dr\",\n",
    "    })\n",
    "    return df\n",
    "\n",
    "# we must add the \"fj_isVBF\" & \"fj_isggF\" labels that we forgot to include in the processor\n",
    "def postprocess(df, sample):\n",
    "    if \"HToWW\" in sample:        \n",
    "        if \"VBF\" in sample:\n",
    "            df[\"fj_isggF\"] = 0\n",
    "            df[\"fj_isVBF\"] = 1\n",
    "        elif \"GluGluHToWW\" in sample:\n",
    "            df[\"fj_isggF\"] = 1\n",
    "            df[\"fj_isVBF\"] = 0      \n",
    "    else:\n",
    "        df[\"fj_isggF\"] = 0\n",
    "        df[\"fj_isVBF\"] = 0  \n",
    "\n",
    "    df = rename_vars(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4058920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events will follow a 80/20 split \n",
    "# samples_num = {\n",
    "# #     \"GluGluHToWW_Pt-200ToInf_M-125\": 100_000_000_000_000,    # basically all\n",
    "#     \"GluGluHToWW_Pt-200ToInf_M-125\": 10,    # basically all\n",
    "\n",
    "#     \"QCD_Pt_170to300\": 10,\n",
    "#     \"QCD_Pt_300to470\": 10,\n",
    "#     \"QCD_Pt_470to600\": 10,\n",
    "#     \"QCD_Pt_600to800\": 10,\n",
    "    \n",
    "#     \"TTToSemiLeptonic\": 10,\n",
    "    \n",
    "#     \"WJetsToLNu_HT-200To400\": 10,\n",
    "#     \"WJetsToLNu_HT-400To600\": 10,\n",
    "#     \"WJetsToLNu_HT-600To800\": 10,\n",
    "# }\n",
    "\n",
    "# # v35_10*\n",
    "# samples_num = {\n",
    "#     \"GluGluHToWW_Pt-200ToInf_M-125\": 100_000,    # basically all\n",
    "# #     \"GluGluHToWW_Pt-200ToInf_M-125\": 10,    # basically all\n",
    "\n",
    "#     \"QCD_Pt_170to300\": 2_500,\n",
    "#     \"QCD_Pt_300to470\": 2_500,\n",
    "#     \"QCD_Pt_470to600\": 2_500,\n",
    "#     \"QCD_Pt_600to800\": 2_500,\n",
    "    \n",
    "#     \"TTToSemiLeptonic\": 100_000,\n",
    "    \n",
    "#     \"WJetsToLNu_HT-200To400\": 30_000,\n",
    "#     \"WJetsToLNu_HT-400To600\": 40_000,\n",
    "#     \"WJetsToLNu_HT-600To800\": 30_000,\n",
    "# }\n",
    "\n",
    "\n",
    "# # v35_11*\n",
    "# samples_num = {\n",
    "#     \"GluGluHToWW_Pt-200ToInf_M-125\": 100_000,    # basically all\n",
    "# #     \"GluGluHToWW_Pt-200ToInf_M-125\": 10,    # basically all\n",
    "\n",
    "#     \"QCD_Pt_170to300\": 10_000,\n",
    "#     \"QCD_Pt_300to470\": 10_000,\n",
    "#     \"QCD_Pt_470to600\": 10_000,\n",
    "#     \"QCD_Pt_600to800\": 10_000,\n",
    "    \n",
    "#     \"TTToSemiLeptonic\": 200_000,\n",
    "    \n",
    "#     \"WJetsToLNu_HT-200To400\": 60_000,\n",
    "#     \"WJetsToLNu_HT-400To600\": 80_000,\n",
    "#     \"WJetsToLNu_HT-600To800\": 60_000,\n",
    "# }\n",
    "\n",
    "# v35_12*\n",
    "samples_num = {\n",
    "    \"GluGluHToWW_Pt-200ToInf_M-125\": 200_000,    # basically all\n",
    "\n",
    "    \"QCD_Pt_170to300\": 50_000,\n",
    "    \"QCD_Pt_300to470\": 50_000,\n",
    "    \"QCD_Pt_470to600\": 50_000,\n",
    "    \"QCD_Pt_600to800\": 50_000,\n",
    "    \n",
    "    \"TTToSemiLeptonic\": 300_000,\n",
    "    \n",
    "    \"WJetsToLNu_HT-200To400\": 100_000,\n",
    "    \"WJetsToLNu_HT-400To600\": 200_000,\n",
    "    \"WJetsToLNu_HT-600To800\": 100_000,\n",
    "}\n",
    "\n",
    "# # v35_13*\n",
    "# samples_num = {\n",
    "#     \"GluGluHToWW_Pt-200ToInf_M-125\": 100_000,    # basically all\n",
    "# #     \"GluGluHToWW_Pt-200ToInf_M-125\": 10,    # basically all\n",
    "\n",
    "#     \"QCD_Pt_170to300\": 100_000,\n",
    "#     \"QCD_Pt_300to470\": 100_000,\n",
    "#     \"QCD_Pt_470to600\": 100_000,\n",
    "#     \"QCD_Pt_600to800\": 100_000,\n",
    "    \n",
    "#     \"TTToSemiLeptonic\": 500_000,\n",
    "    \n",
    "#     \"WJetsToLNu_HT-200To400\": 200_000,\n",
    "#     \"WJetsToLNu_HT-400To600\": 400_000,\n",
    "#     \"WJetsToLNu_HT-600To800\": 200_000,\n",
    "# }\n",
    "\n",
    "# # v35_14*\n",
    "# samples_num = {\n",
    "#     \"GluGluHToWW_Pt-200ToInf_M-125\": 100_000,    # basically all\n",
    "# #     \"GluGluHToWW_Pt-200ToInf_M-125\": 10,    # basically all\n",
    "\n",
    "#     \"QCD_Pt_170to300\": 200_000,\n",
    "#     \"QCD_Pt_300to470\": 200_000,\n",
    "#     \"QCD_Pt_470to600\": 200_000,\n",
    "#     \"QCD_Pt_600to800\": 100_000,\n",
    "    \n",
    "#     \"TTToSemiLeptonic\": 800_000,\n",
    "    \n",
    "#     \"WJetsToLNu_HT-200To400\": 200_000,\n",
    "#     \"WJetsToLNu_HT-400To600\": 600_000,\n",
    "#     \"WJetsToLNu_HT-600To800\": 200_000,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b96bcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TTToSemiLeptonic\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'postprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m outdir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdir_TaggerInput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/outfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/*.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 19\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpostprocess\u001b[49m(df, sample)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# apply selection in config v35\u001b[39;00m\n\u001b[1;32m     22\u001b[0m msk1 \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlep_fj_dr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.03\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlep_fj_dr\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.8\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'postprocess' is not defined"
     ]
    }
   ],
   "source": [
    "OUTPATH = \"../datafiles/TaggerInput_Small/\"\n",
    "\n",
    "for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):\n",
    "    if \".DS_Store\" in dir_TaggerInput:\n",
    "        continue\n",
    "    \n",
    "    for sample in os.listdir(f\"{OUTPATH}/{dir_TaggerInput}/\"):\n",
    "        if \"DS_Store\" in sample:\n",
    "            continue              \n",
    "        \n",
    "#         if \"TTToSemiLeptonic\" not in sample:\n",
    "#             continue\n",
    "        \n",
    "        print(f\"Processing {sample}\")\n",
    "\n",
    "        outdir = f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles\"\n",
    "        \n",
    "        df = pd.read_parquet(glob.glob(f\"{outdir}/*.parquet\"))\n",
    "        df = postprocess(df, sample)\n",
    "\n",
    "        # apply selection in config v35\n",
    "        msk1 = (df[\"lep_fj_dr\"] > 0.03) & (df[\"lep_fj_dr\"] < 0.8)\n",
    "        msk_H = (df[\"fj_genRes_mass\"] == 125) & (df[\"fj_isHVV_Matched\"] == 1) & (df[\"fj_lepinprongs\"] == 1) & (df[\"fj_nquarks\"] == 2)\n",
    "        msk_noH = (df[\"fj_genRes_mass\"] != 125)\n",
    "\n",
    "        df = df[msk1 & (msk_H | msk_noH)]\n",
    "\n",
    "        # select the number of events specefied\n",
    "        df = df.head(samples_num[sample])\n",
    "        \n",
    "        df_train, df_test = sklearn.model_selection.train_test_split(df, test_size=0.1)\n",
    "\n",
    "        os.system(f\"mkdir -p {outdir}/train\")\n",
    "        with uproot.recreate(f\"{outdir}/train/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "            rfile[\"Events\"] = ak.Array(df_train.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "        os.system(f\"mkdir -p {outdir}/test\")            \n",
    "        with uproot.recreate(f\"{outdir}/test/out.root\", compression=uproot.LZ4(4)) as rfile:\n",
    "            rfile[\"Events\"] = ak.Array(df_test.to_dict(orient=\"list\", index=True))\n",
    "\n",
    "        print(\"--------------------------\")    \n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3203724",
   "metadata": {},
   "source": [
    "# Check Number of events in ntuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d3023b5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GluGluHToWW_Pt-200ToInf_M-125 train 90000\n",
      "GluGluHToWW_Pt-200ToInf_M-125 test 10000\n",
      "--------------------------\n",
      "TTToSemiLeptonic train 270000\n",
      "TTToSemiLeptonic test 30000\n",
      "--------------------------\n",
      "WJetsToLNu_HT-200To400 train 90000\n",
      "WJetsToLNu_HT-200To400 test 10000\n",
      "--------------------------\n",
      "WJetsToLNu_HT-400To600 train 180000\n",
      "WJetsToLNu_HT-400To600 test 20000\n",
      "--------------------------\n",
      "WJetsToLNu_HT-600To800 train 90000\n",
      "WJetsToLNu_HT-600To800 test 10000\n",
      "--------------------------\n",
      "QCD_Pt_170to300 train 45000\n",
      "QCD_Pt_170to300 test 5000\n",
      "--------------------------\n",
      "QCD_Pt_300to470 train 45000\n",
      "QCD_Pt_300to470 test 5000\n",
      "--------------------------\n",
      "QCD_Pt_470to600 train 45000\n",
      "QCD_Pt_470to600 test 5000\n",
      "--------------------------\n",
      "QCD_Pt_600to800 train 45000\n",
      "QCD_Pt_600to800 test 5000\n",
      "--------------------------\n",
      "Total train 900000\n",
      "Total test 100000\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "    \"GluGluHToWW_Pt-200ToInf_M-125\",  \n",
    "    \"TTToSemiLeptonic\",   \n",
    "    \"WJetsToLNu_HT-200To400\",\n",
    "    \"WJetsToLNu_HT-400To600\",\n",
    "    \"WJetsToLNu_HT-600To800\",\n",
    "    \"QCD_Pt_170to300\",\n",
    "    \"QCD_Pt_300to470\",\n",
    "    \"QCD_Pt_470to600\",\n",
    "    \"QCD_Pt_600to800\",\n",
    "]\n",
    "\n",
    "OUTPATH = \"../datafiles/TaggerInput_Small/\"\n",
    "\n",
    "num_events = {}\n",
    "\n",
    "\n",
    "numtrain_total, numtest_total = 0, 0\n",
    "for sample in samples:\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue              \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/train/out.root\")[\"Events\"]\n",
    "            num += events.num_entries\n",
    "            \n",
    "            numtrain_total += num\n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"train\", num)\n",
    "\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue    \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/out.root\")[\"Events\"]\n",
    "            num += events.num_entries\n",
    "            \n",
    "            numtest_total += num            \n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"test\", num)\n",
    "    \n",
    "    print(\"--------------------------\")\n",
    "    \n",
    "print(\"Total train\", numtrain_total)\n",
    "print(\"Total test\", numtest_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c842d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a057e95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ad430f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f915f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTToSemiLeptonic train 0\n",
      "TTToSemiLeptonic test 30000\n",
      "--------------------------\n",
      "Total train 0\n",
      "Total test 30000\n"
     ]
    }
   ],
   "source": [
    "samples = [\n",
    "#     \"GluGluHToWW_Pt-200ToInf_M-125\",  \n",
    "    \"TTToSemiLeptonic\",   \n",
    "#     \"WJetsToLNu_HT-200To400\",\n",
    "#     \"WJetsToLNu_HT-400To600\",\n",
    "#     \"WJetsToLNu_HT-600To800\",\n",
    "#     \"QCD_Pt_170to300\",\n",
    "#     \"QCD_Pt_300to470\",\n",
    "#     \"QCD_Pt_470to600\",\n",
    "#     \"QCD_Pt_600to800\",\n",
    "]\n",
    "\n",
    "OUTPATH = \"../datafiles/TaggerInput_Small/\"\n",
    "\n",
    "num_events = {}\n",
    "\n",
    "\n",
    "numtrain_total, numtest_total = 0, 0\n",
    "for sample in samples:\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue              \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/train/out.root\")[\"Events\"]\n",
    "            num += events.num_entries\n",
    "            \n",
    "            numtrain_total += num\n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"train\", num)\n",
    "\n",
    "\n",
    "    num = 0    \n",
    "    for dir_TaggerInput in os.listdir(f\"{OUTPATH}/\"):   \n",
    "        if \"DS_Store\" in dir_TaggerInput:\n",
    "            continue    \n",
    "            \n",
    "        try:\n",
    "            events = uproot.open(f\"{OUTPATH}/{dir_TaggerInput}/{sample}/outfiles/test/out.root\")[\"Events\"]\n",
    "            num += events.num_entries\n",
    "            \n",
    "            numtest_total += num            \n",
    "        except:\n",
    "            continue\n",
    "    print(sample, \"test\", num)\n",
    "    \n",
    "    print(\"--------------------------\")\n",
    "    \n",
    "print(\"Total train\", numtrain_total)\n",
    "print(\"Total test\", numtest_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e304d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-env",
   "language": "python",
   "name": "coffea-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
